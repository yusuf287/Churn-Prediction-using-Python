{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement:\n",
    "\n",
    "** Explore the datasets and develop a model to predict customer churn over time. **\n",
    "\n",
    "**By:** Yusuf Firoz"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The process is divided the whole model building into 4 parts:\n",
    "    Step 1. Data PreProcessing\n",
    "    Step 2. Final Dataset Prepearation\n",
    "    Step 3. Model Building and Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Final Dataset Prepearation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Main steps: **\n",
    "* Import all the required libraries and the 4 pickle objects created in **Step 1**.\n",
    "* Join all the 4 tables on **subscription_id**. \n",
    "* We have total **1684288** entries and 70 columns.\n",
    "* Generate new feature named **Total_delivery_duration** which is the total duration between first and last delivery date.\n",
    "* Generate new feature named **Gap_of_Cancellation** which is the total duration between cancellation date and last delivery date.\n",
    "* Add churn status of subscriber.\n",
    "\n",
    "** Data Cleaning: **\n",
    "\n",
    "** In this step we will remove all the illogical data:**\n",
    "    * Delivery date cannot be after cancellation date i.e. Last_event_date.\n",
    "    * This will remove 63884 rows.\n",
    "    * First error reporting date cannot be greater than first delivery date.\n",
    "    * This will remove 94390 rows.\n",
    "    * First Pause date cannot be before first delivery date\n",
    "    * This will remove 738768 rows\n",
    "\n",
    "* We have total 787246 entries and 70 columns after cleaning\n",
    "* Drop all the categorical columns.\n",
    "* Fill all the null columns with **0**\n",
    "* Generate a pickle object for the final dataset.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import required libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime  \n",
    "from time import time \n",
    "import pickle \n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import all the pickle objects **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boxes = pd.read_pickle('boxes.pickle')\n",
    "errors = pd.read_pickle('errors.pickle')\n",
    "pauses = pd.read_pickle('pauses.pickle')\n",
    "cancels = pd.read_pickle('cancels.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Join Tables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Joining all the data frames on 'subscription_id'\n",
    "\n",
    "boxes_pauses = pd.merge(boxes,pauses,how='left',on='subscription_id')\n",
    "boxes_pauses_errors = pd.merge(boxes_pauses,errors,how='left',on='subscription_id')\n",
    "final = pd.merge(boxes_pauses_errors,cancels,how='left',on='subscription_id')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create new Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Total duration between first and last delivery date.\n",
    "final['Total_delivery_duration'] = final['Last_delivery_date'].subtract(final['First_delivery_date']) \n",
    "\n",
    "#Total duration between cancellation date and last delivery date.\n",
    "final['Gap_of_Cancellation'] = final['Last_event_date'].subtract(final['Last_delivery_date']) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add the label**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Tag the data by adding churn status of subscriber:\n",
    "final['churn_status'] = pd.notnull(final['Last_event_date']).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Remove illogical Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Delivery date cannot be after cancellation date i.e. Last_event_date\n",
    "#This will remove 63884 rows.\n",
    "#final[final['Last_delivery_date'] > final['Last_event_date']]\n",
    "final.drop(final.ix[final['Last_delivery_date'] > final['Last_event_date']].index, inplace=True)\n",
    "#We have total 1620404 entries and 70 columns after cleaning\n",
    "\n",
    "#First error reporting date cannot be greater than first delivery date.\n",
    "#This will remove 94390 rows.\n",
    "#final[final['First_delivery_date'] > final['first_reported_date']]\n",
    "final.drop(final.ix[final['First_delivery_date'] > final['first_reported_date']].index, inplace=True)\n",
    "#We have total 1526014  entries and 70 columns after cleaning\n",
    "\n",
    "#First Pause date cannot be before first delivery date\n",
    "#This will remove 738768 rows\n",
    "#final[final['First_pause_start'] > final['First_delivery_date']]\n",
    "final.drop(final.ix[final['First_pause_start'] > final['First_delivery_date']].index, inplace=True)\n",
    "#We have total 787246 entries and 70 columns after cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** Remove categorical features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Delete extra columns like date, Product type, Channel type etc.\n",
    "final.drop(['started_week','Product','Channel','First_delivery_date',\n",
    "            'Last_delivery_date','First_pause_start','Last_pause_end','first_reported_date',\n",
    "           'last_reported_date','First_event_date','Last_event_date'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* **Fill all the null with 0**\n",
    "* **Convert days to integer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fill all the nulls with NA\n",
    "final = final.fillna(0)\n",
    "#convert days timstamp to int:\n",
    "final['Total_pause_duration'] = final['Total_pause_duration'].dt.days   \n",
    "final['Total_delivery_duration'] = final['Total_delivery_duration'].dt.days        \n",
    "final['Gap_of_Cancellation'] = final['Gap_of_Cancellation'].dt.days\n",
    "\n",
    "# Convert subscription_id to the index of final dataset\n",
    "final.set_index('subscription_id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "** Pickle file for Pauses** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create pickle file for Final datset\n",
    "with open('final.pickle', 'wb') as f:\n",
    "    pickle.dump(final, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
